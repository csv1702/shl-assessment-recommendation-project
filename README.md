# ğŸ“˜ SHL Assessment Recommendation Engine

## Overview

This project implements an **end-to-end Assessment Recommendation Engine** using **SHLâ€™s product catalogue**.

The system accepts a **natural-language hiring or assessment requirement** and returns a ranked list of **relevant SHL individual test solutions**, using **semantic search and vector similarity**.

The solution includes:

- Live crawling of SHL assessment catalogue
- Semantic embedding and vector search
- Objective evaluation using labeled data
- REST API (as per SHL Appendix-2)
- Simple web frontend for testing
- Submission-ready prediction output
- Live Deployed Link to FrontEnd- "https://shl-assessment-recommendation-project-aurkcstwfmzrusbhelr9yy.streamlit.app/"

---

## System Architecture

```
User Query
   â†“
Sentence Transformer (Embeddings)
   â†“
FAISS Vector Index
   â†“
Top-K Relevant SHL Assessments
   â†“
FastAPI API â†’ Streamlit Frontend
```

---

## Key Technologies Used

- **Python 3.10**
- **Sentence Transformers** (`all-MiniLM-L6-v2`)
- **FAISS** (vector similarity search)
- **FastAPI** (REST API)
- **Streamlit** (frontend UI)
- **Pandas / NumPy**
- **Requests**
- **BeautifulSoup** (for crawling)

---

## Data Collection

### SHL Catalogue Crawling

- The SHL product catalogue was crawled directly from the SHL website.
- Only **Individual Test Solutions** were considered.
- **Pre-packaged Job Solutions were explicitly excluded**, as required.

ğŸ“Š **Total Individual Test Solutions Collected:** **264**

> âš ï¸ _Note:_ While the assignment specifies a target of 377+, the SHL website structure limits discoverability of some assessments through public catalogue endpoints. The crawling logic was carefully designed to avoid invalid, duplicate, or non-assessment URLs. This limitation is transparently acknowledged and discussed in the approach document.

---

## Embedding & Retrieval

- Each assessment description was converted into a dense vector using:

  ```
  sentence-transformers/all-MiniLM-L6-v2
  ```

- All vectors were indexed using **FAISS (IndexFlatIP)** with cosine similarity.
- Queries are embedded in the same vector space and matched against the index.

This approach enables **semantic retrieval**, allowing the system to understand intent rather than relying on keywords.

---

## Evaluation (Labeled Train Data)

The provided **labeled train dataset** was used to evaluate recommendation quality.

### Metrics Used

- **Recall@5**
- **Recall@10**
- **Mean Recall**

### Evaluation Highlights

- URLs from different SHL formats were normalized using assessment slugs.
- Results demonstrate meaningful retrieval of human-labeled relevant assessments.

Evaluation code is available in:

```
pipeline/evaluate.py
```

---

## Test Set Predictions

Predictions were generated for the **unlabeled test queries**, as required.

### Output Format (Appendix-3 Compliant)

```
Query,Assessment_url
Query 1,URL 1
Query 1,URL 2
Query 2,URL 1
...
```

ğŸ“„ Output file:

```
submission_predictions_final.csv
```

---

## REST API (Appendix-2)

A **FastAPI backend** exposes the recommendation engine.

### Available Endpoints

#### Health Check

```
GET /health
```

Response:

```json
{ "status": "ok" }
```

#### Recommendation Endpoint

```
POST /recommend
```

Request:

```json
{
  "query": "Looking for a cognitive assessment for graduates"
}
```

Response:

```json
[
  {
    "url": "...",
    "name": "...",
    "description": "...",
    "duration": "...",
    "remote_support": "...",
    "adaptive_support": "...",
    "test_type": "Individual Test"
  }
]
```

Swagger UI available at:

```
http://127.0.0.1:8000/docs
```

---

## Web Frontend

A **simple Streamlit frontend** is provided to test the system interactively.

### Features

- Text input for natural-language queries
- Displays top-K recommended assessments
- Connects directly to the FastAPI backend

### Run Frontend

```bash
python -m streamlit run frontend/app.py
```

Frontend URL:

```
http://localhost:8501
```

---

## Project Structure

```
shl-assessment-recommendation-project/
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ app.py                 # FastAPI backend
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                 # Streamlit frontend
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ generate_embeddings.py
â”‚   â”œâ”€â”€ build_faiss_index.py
â”‚   â”œâ”€â”€ query_engine.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ predict_test.py
â”‚
â”œâ”€â”€ scraper/
â”‚   â””â”€â”€ shl_scraper.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ given/
â”‚   â”‚   â””â”€â”€ Gen_AI Dataset.xlsx
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ embedding_corpus.json
â”‚       â”œâ”€â”€ embeddings.npy
â”‚       â””â”€â”€ faiss.index
â”‚
â”œâ”€â”€ submission_predictions_final.csv
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## How to Run (Quick Start)

1ï¸âƒ£ Activate virtual environment

```bash
venv\Scripts\activate
```

2ï¸âƒ£ Run API

```bash
python -m uvicorn api.app:app --reload
```

3ï¸âƒ£ Run Frontend

```bash
python -m streamlit run frontend/app.py
```

---

## Future Improvements

- Expand crawling to additional SHL catalogue entry points
- Improve metadata extraction (duration, adaptive support, etc.)
- Add reranking using cross-encoder models
- Deploy API & frontend to cloud infrastructure

---

## Conclusion

This project demonstrates a **complete, production-style recommendation system**, including data ingestion, semantic retrieval, evaluation, API exposure, and frontend testing.
It follows SHLâ€™s specifications closely while maintaining transparency around known limitations.

---

**Author:**
Chandra Shekhar
GitHub: `csv1702`
